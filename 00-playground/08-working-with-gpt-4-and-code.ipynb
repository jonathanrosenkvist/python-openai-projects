{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "config = dotenv_values(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = config[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = \"\"\"\n",
    "def remove_common_prefix(x, prefix, ws_prefix):\n",
    "    x[\"completion\"] = x[\"completion\"].str[len(prefix) :]\n",
    "    if ws_prefix:\n",
    "        # keep the single whitespace as prefix\n",
    "        x[\"completion\"] = \" \" + x[\"completion\"]\n",
    "    return x\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    { \"role\": \"system\", \"content\": \"you are a Python explaining assistant\" },\n",
    "    { \"role\": \"user\", \"content\": f\"Explain the following function: {func}\" }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    max_tokens=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.choices[0].message.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubble_sort = \"\"\"\n",
    "def sort(array):    \n",
    "  for i in range(len(array)):\n",
    "    for j in range(0, len(array) - i - 1):\n",
    "      if array[j] > array[j + 1]:\n",
    "        temp = array[j]\n",
    "        array[j] = array[j+1]\n",
    "        array[j+1] = temp\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_sort = \"\"\"\n",
    "def partition(array, low, high):\n",
    "    pivot = array[high]\n",
    "    i = low - 1\n",
    " \n",
    "    for j in range(low, high):\n",
    "        if array[j] <= pivot:\n",
    "            i = i + 1\n",
    "            (array[i], array[j]) = (array[j], array[i])\n",
    "    (array[i + 1], array[high]) = (array[high], array[i + 1])\n",
    "    return i + 1\n",
    "  \n",
    "def sort(array, low, high):\n",
    "    if low < high:\n",
    "        pi = partition(array, low, high)\n",
    "        sort(array, low, pi - 1)\n",
    "        sort(array, pi + 1, high)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = {\n",
    "    # {\"role\": \"user\", \"content\": f\"Calculate the time complexity of the following function: {bubble_sort}\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Calculate the time complexity of the following function: {quick_sort}\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    max_tokens=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.choices[0].message.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate JavaScript to Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# js = \"\"\"\n",
    "# function mystery(arr) {\n",
    "#   return arr.reduce(function (p, v) {\n",
    "#     return ( p < v ? p : v );\n",
    "#   });\n",
    "# }\n",
    "# \"\"\"\n",
    "\n",
    "# js = \"\"\"\n",
    "# const mystery = (email) => {\n",
    "#   const regex = /^\\S+@\\S+\\.\\S+$/;\n",
    "#   return regex.test(email);\n",
    "# };\n",
    "# \"\"\"\n",
    "\n",
    "js = \"\"\"\n",
    "const mystery = (str) => {\n",
    "  const arr = str.trim().toLowerCase().split(\" \");\n",
    "\n",
    "  for (let i = 0; i < arr.length; i++) {\n",
    "    arr[i] = arr[i].charAt(0).toUpperCase() + arr[i].slice(1);\n",
    "  }\n",
    "\n",
    "  return arr.join(\" \");\n",
    "};\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    { \"role\": \"user\", \"content\": f\"Translate the following JavaScript to Python: {js}\" }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    max_tokens=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.choices[0].message.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "def add_underscore(word):\n",
    "    new_word = \"_\"\n",
    "    for i in range(len(word)):\n",
    "        new_word = word[i] + \"_\"\n",
    "    return new_word\n",
    "\n",
    "phrase = \"hello\"\n",
    "print(add_underscore(phrase))\n",
    "\"\"\"\n",
    "\n",
    "# to fix it:\n",
    "# new_word += word[i] + \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    { \"role\": \"user\", \"content\": f\"Fix and explain the bug in the following Python code: {code}\" }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    max_tokens=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_h_e_l_l_o_\n"
     ]
    }
   ],
   "source": [
    "# working code\n",
    "\n",
    "def add_underscore(word):\n",
    "    new_word = \"_\"\n",
    "    for i in range(len(word)):\n",
    "        new_word += word[i] + \"_\"\n",
    "    return new_word\n",
    "\n",
    "phrase = \"hello\"\n",
    "print(add_underscore(phrase))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate code from scratch with GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give the specific format you need\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": f\"Write a Python function that accepts an RGB color in the format 'rgb(85,145,0)' and returns the corresponding HSL color in the format 'hsl(85 100% 28%)'\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    max_tokens=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hsl(84 100% 28%)\n"
     ]
    }
   ],
   "source": [
    "def rgb_to_hsl(rgb_str):\n",
    "    import colorsys\n",
    "    \n",
    "    # Extract the RGB values from the string.\n",
    "    r, g, b = [int(x) for x in rgb_str[4:-1].split(',')]\n",
    "\n",
    "    # Convert RGB to float values ranging from 0 to 1.\n",
    "    r /= 255.0\n",
    "    g /= 255.0\n",
    "    b /= 255.0\n",
    "\n",
    "    # Convert RGB to HSL values.\n",
    "    h, l, s = colorsys.rgb_to_hls(r, g, b)\n",
    "\n",
    "    # Convert HSL to the proper format.\n",
    "    h = int(h * 360)\n",
    "    s = int(s * 100)\n",
    "    l = int(l * 100)\n",
    "\n",
    "    # Return the resulting HSL string.\n",
    "    return f'hsl({h} {s}% {l}%)'\n",
    "\n",
    "rgb_color = \"rgb(85,145,0)\"\n",
    "hsl_color = rgb_to_hsl(rgb_color)\n",
    "print(hsl_color)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
